{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ LogSumExp(x_1 ... x_n) = \\log(\\sum_{i=1}^n e^{x_i}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import logsumexp # 计算数据非常小时可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNaiveBayes:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._classes = None\n",
    "        \n",
    "    def _joint_log_likehood(self, X):\n",
    "        \"\"\"Compute the unnormalized posterior log probability of X\n",
    "\n",
    "        I.e. ``log P(c) + log P(x|c)`` for all rows x of X, as an array-like of\n",
    "        shape [n_classes, n_samples].\n",
    "\n",
    "        Input is passed to _joint_log_likelihood as-is by predict,\n",
    "        predict_proba and predict_log_proba.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict_log_proba(self, X):\n",
    "        \"\"\"\n",
    "        Return log-probability estimates for the test vector X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C : array-like, shape = [n_samples, n_classes]\n",
    "            Returns the log-probability of the samples for each class in\n",
    "            the model. The columns correspond to the classes in sorted\n",
    "            order, as they appear in the attribute `classes_`.\n",
    "        \"\"\"\n",
    "        jll = self._joint_log_likehood(X)\n",
    "        # normalize by P(x) = P(f_1, ..., f_n) 归一化\n",
    "        log_prob_x = logsumexp(jll, axis=1)\n",
    "        return jll - np.atleast_2d(log_prob_x).T\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Return probability estimates for the test vector X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C : array-like, shape = [n_samples, n_classes]\n",
    "            Returns the probability of the samples for each class in\n",
    "            the model. The columns correspond to the classes in sorted\n",
    "            order, as they appear in the attribute `classes_`.\n",
    "        \"\"\"\n",
    "        return np.exp(self.predict_log_proba(X))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform classification on an array of test vectors X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C : array, shape = [n_samples]\n",
    "            Predicted target values for X\n",
    "        \"\"\"\n",
    "        jll = self._joint_log_likehood(X)\n",
    "        return self._classes[np.argmax(jll, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯分布\n",
    "$$ p(x = v | C_k) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2 }}e^{- \\frac{(v - \\mu_k)^2}{2\\sigma_k^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianNaiveBayes(BaseNaiveBayes):\n",
    "    \"\"\"高斯贝叶斯\"\"\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: train dataset, shape = (n_samples, n_features)\n",
    "        y: target, shape = (n_samples, )\n",
    "        \"\"\"\n",
    "        # 计算y的先验概率\n",
    "        y_prior_proba = []\n",
    "        self._classes = np.unique(y) # 找到y类别\n",
    "        for c in self._classes:\n",
    "            c_count = (y==c).sum() # 计算c类有多少\n",
    "            y_prior_proba.append(c_count / np.size(y))\n",
    "        self._y_prior_proba = np.array(y_prior_proba)\n",
    "        \n",
    "        # 计算连续变量X的高斯分布参数 sigma方差  mu均值\n",
    "        features = X.shape[1]\n",
    "        self._mu = np.zeros((np.size(self._classes), features))  # y类别 和x特征\n",
    "        self._sigma = np.zeros((np.size(self._classes), features))\n",
    "        for i in range(np.size(self._classes)):\n",
    "            x_c = X[y == self._classes[i]]  # 筛选y = i 的样本\n",
    "            self._mu[i,:] = np.mean(x_c, axis=0) # X列：特征\n",
    "            self._sigma[i,:] = np.var(x_c, axis=0)\n",
    "        return self\n",
    "            \n",
    "    def _joint_log_likehood(self, X):\n",
    "        jll = []\n",
    "        for i in range(np.size(self._classes)):\n",
    "            log_prior = np.log(self._y_prior_proba[i]) # log\n",
    "            # 高斯公式取对数\n",
    "            x_given_y = - 0.5 * np.sum(np.log(2 * np.pi * self._sigma[i,:]))\n",
    "            x_given_y -= 0.5 * np.sum(((X - self._mu[i,:]) ** 2) / (self._sigma[i,:]), axis=1)\n",
    "            jll.append(log_prior + x_given_y)\n",
    "        jll = np.array(jll).T\n",
    "        return jll\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<GaussianNaiveBayes>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: `logsumexp` is deprecated!\n",
      "Importing `logsumexp` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.logsumexp` instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "test = np.array([[1, 'S'], [1, 'M'], [1, 'M'], [1, 'S'], [1, 'S'], [2, 'S'], [2, 'M'], \n",
    "                    [2, 'M'], [2, 'L'], [2, 'L'], [3, 'L'], [3, 'M'], [3, 'M'], [3, 'L'], [3, 'L']])\n",
    "iris = load_iris()\n",
    "X = iris.data \n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "gnb = GaussianNaiveBayes().fit(X_train, y_train)\n",
    "log_proba = gnb.predict_log_proba(X_test)\n",
    "proba = gnb.predict_proba(X_test)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 伯努利"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多项式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
